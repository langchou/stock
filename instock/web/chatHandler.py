#!/usr/local/bin/python3
# -*- coding: utf-8 -*-

import json
import logging
import os
import re
import datetime
from abc import ABC

import requests
import tornado.web
from tornado import gen

import instock.web.base as webBase

__author__ = 'jonty'
__date__ = '2025/2/12'

# ---------------------------------------------------------------------------
# AI configuration via environment variables
# ---------------------------------------------------------------------------
AI_BASE_URL = os.environ.get('AI_BASE_URL', 'https://api.openai.com/v1')
AI_API_KEY = os.environ.get('AI_API_KEY', '')
AI_MODEL = os.environ.get('AI_MODEL', 'gpt-4o')

# ---------------------------------------------------------------------------
# SQL safety: only SELECT is allowed
# ---------------------------------------------------------------------------
_BLOCKED_KEYWORDS = re.compile(
    r'\b(INSERT|UPDATE|DELETE|DROP|ALTER|CREATE|TRUNCATE|REPLACE|RENAME|GRANT|REVOKE|LOCK|UNLOCK)\b',
    re.IGNORECASE,
)

_LIMIT_PATTERN = re.compile(r'\bLIMIT\s+\d+', re.IGNORECASE)

_MAX_ROWS = 50


def _validate_sql(sql: str) -> str:
    """Validate and sanitise a SQL statement generated by the LLM.

    Returns the (possibly amended) SQL string.
    Raises ``ValueError`` when the statement is not a safe SELECT.
    """
    stripped = sql.strip().rstrip(';').strip()

    if not stripped.upper().startswith('SELECT'):
        raise ValueError("Only SELECT statements are allowed.")

    if _BLOCKED_KEYWORDS.search(stripped):
        raise ValueError("The generated SQL contains prohibited keywords.")

    # Auto-append LIMIT when absent
    if not _LIMIT_PATTERN.search(stripped):
        stripped = f"{stripped} LIMIT {_MAX_ROWS}"

    return stripped


# ---------------------------------------------------------------------------
# JSON encoder that handles date / bytes coming from torndb Row objects
# ---------------------------------------------------------------------------
class _ChatEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, bytes):
            return "yes" if (len(obj) > 0 and obj[0] == 1) else "no"
        if isinstance(obj, (datetime.date, datetime.datetime)):
            return obj.strftime("%Y-%m-%d")
        return super().default(obj)


# ---------------------------------------------------------------------------
# System prompt with full database schema for the SQL-generation step
# ---------------------------------------------------------------------------
SYSTEM_PROMPT_SQL = """你是InStock股票系统的数据分析AI助手。你的任务是根据用户的自然语言问题，生成正确的SQL查询语句来检索数据。

## 数据库表结构（数据库名: instockdb, MySQL/MariaDB）

### cn_stock_spot -- 每日股票数据（最常用）
列：date(日期DATE), code(代码VARCHAR(6)), name(名称), new_price(最新价), change_rate(涨跌幅%),
ups_downs(涨跌额), volume(成交量), deal_amount(成交额), amplitude(振幅), turnoverrate(换手率),
volume_ratio(量比), open_price(今开), high_price(最高), low_price(最低), pre_close_price(昨收),
dtsyl(市盈率动), pe9(市盈率TTM), pbnewmrq(市净率), basic_eps(每股收益), bvps(每股净资产),
roe_weight(加权净资产收益率), sale_gpr(毛利率), debt_asset_ratio(资产负债率),
total_operate_income(营业收入), toi_yoy_ratio(营收同比增长%), parent_netprofit(归属净利润),
netprofit_yoy_ratio(净利润同比增长%), total_market_cap(总市值), free_cap(流通市值),
industry(所处行业), listing_date(上市时间)

### cn_etf_spot -- 每日ETF数据
列：date, code, name, new_price, change_rate, volume, deal_amount, turnoverrate, total_market_cap, free_cap

### cn_stock_fund_flow -- 股票资金流向
列：date, code, name, new_price, change_rate,
fund_amount(今日主力净流入净额), fund_rate(今日主力净流入净占比%),
fund_amount_super(超大单净流入), fund_rate_super, fund_amount_large(大单净流入), fund_rate_large,
fund_amount_medium(中单净流入), fund_rate_medium, fund_amount_small(小单净流入), fund_rate_small,
change_rate_3(3日涨跌幅), fund_amount_3(3日主力净流入), fund_rate_3,
fund_amount_super_3, fund_rate_super_3, fund_amount_large_3, fund_rate_large_3,
fund_amount_medium_3, fund_rate_medium_3, fund_amount_small_3, fund_rate_small_3,
change_rate_5(5日涨跌幅), fund_amount_5(5日主力净流入), fund_rate_5,
fund_amount_super_5, fund_rate_super_5, fund_amount_large_5, fund_rate_large_5,
fund_amount_medium_5, fund_rate_medium_5, fund_amount_small_5, fund_rate_small_5,
change_rate_10(10日涨跌幅), fund_amount_10(10日主力净流入), fund_rate_10,
fund_amount_super_10, fund_rate_super_10, fund_amount_large_10, fund_rate_large_10,
fund_amount_medium_10, fund_rate_medium_10, fund_amount_small_10, fund_rate_small_10

### cn_stock_fund_flow_industry -- 行业资金流向
列：date, name(行业名), change_rate, fund_amount, fund_rate, stock_name(主力净流入最大股),
change_rate_5, fund_amount_5, fund_rate_5, stock_name_5,
change_rate_10, fund_amount_10, fund_rate_10, stock_name_10

### cn_stock_fund_flow_concept -- 概念资金流向（结构同行业资金流向）
列：date, name(概念名), change_rate, fund_amount, fund_rate, stock_name,
change_rate_5, fund_amount_5, fund_rate_5, stock_name_5,
change_rate_10, fund_amount_10, fund_rate_10, stock_name_10

### cn_stock_bonus -- 股票分红配送
列：date, code, name, convertible_total_rate(送转总比例), bonusaward_rate(现金分红),
bonusaward_yield(股息率), plan_date(方案公告日), record_date(股权登记日), progress(方案进度)

### cn_stock_lhb -- 龙虎榜
列：date, code, name, interpret(解读), new_price, change_rate,
net_amount_buy(买入净额), sum_buy(买入总额), sum_sell(卖出总额), reason(上榜原因)

### cn_stock_blocktrade -- 大宗交易
列：date, code, name, new_price, average_price(成交均价), overflow_rate(溢折率%),
trade_number(交易笔数), sum_volume(成交总量), sum_turnover(成交总额)

### cn_stock_selection -- 综合选股（150+列）
关键列：date, code, name, new_price, change_rate, pe9, pbnewmrq,
macd_golden_fork(MACD金叉BIT), kdj_golden_fork(KDJ金叉BIT), break_through(突破BIT)

### cn_stock_indicators -- 股票技术指标
列：date, code, name + 40多个技术指标列：
macd/macds/macdh(MACD), kdjk/kdjd/kdjj(KDJ), boll_ub/boll/boll_lb(布林带),
rsi_6/rsi_12/rsi_24(RSI), cci, atr, adx 等

### cn_stock_pattern -- K线形态识别
列：date, code, name + 60多个K线形态列（值100=看涨, -100=看跌, 0=无信号）
如: hammer(锤头), doji(十字), morning_star(晨星), evening_star(暮星)等

### cn_stock_chip_race_open -- 早盘抢筹
列：date, code, name, new_price, change_rate, bid_rate(抢筹幅度),
bid_trust_amount(抢筹委托金额), bid_deal_amount(抢筹成交金额), bid_ratio(抢筹占比)

### cn_stock_chip_race_end -- 尾盘抢筹（结构同早盘抢筹）
列：date, code, name, new_price, change_rate, bid_rate(抢筹幅度),
bid_trust_amount(抢筹委托金额), bid_deal_amount(抢筹成交金额), bid_ratio(抢筹占比)

### cn_stock_limitup_reason -- 涨停原因
列：date, code, name, title(原因), reason(详因), new_price, change_rate, dde(DDE值)

### 策略表（结构相同：date, code, name + rate_1~rate_100 表示1到100日收益率%）
- cn_stock_strategy_enter -- 放量上涨
- cn_stock_strategy_keep_increasing -- 均线多头
- cn_stock_strategy_parking_apron -- 停机坪
- cn_stock_strategy_backtrace_ma250 -- 回踩年线
- cn_stock_strategy_breakthrough_platform -- 突破平台
- cn_stock_strategy_low_backtrace_increase -- 无大幅回撤
- cn_stock_strategy_turtle_trade -- 海龟交易法则
- cn_stock_strategy_high_tight_flag -- 高而窄旗形
- cn_stock_strategy_climax_limitdown -- 放量跌停
- cn_stock_strategy_low_atr -- 低ATR成长

### cn_stock_attention -- 我的关注
列：datetime(DATETIME), code(VARCHAR(6))

## 规则
1. 只能生成 SELECT 语句，绝对不能生成 INSERT / UPDATE / DELETE / DROP / ALTER / CREATE / TRUNCATE。
2. 日期格式 YYYY-MM-DD。
3. 股票代码code是6位字符串，例如 '000001'。
4. 金额单位为元。
5. change_rate 等百分比字段的值就是百分比数值本身，例如 5.2 代表 5.2%。
6. 查询结果最多返回50行，必须包含 LIMIT，最大 LIMIT 50。
7. 如果用户的问题无法通过查询以上数据库表来回答，请回复 NO_SQL。
8. 请用中文回复。
9. **重要：当用户没有指定日期时，必须使用子查询获取该表中最新的日期，例如 `WHERE date = (SELECT MAX(date) FROM 表名)`。绝对不要硬编码任何日期，也不要用 CURDATE() 或 NOW()，因为最新数据可能不是今天的。**
10. 查询特定股票时，可以用 name LIKE '%关键词%' 或 code = '代码' 来匹配。

## 输出格式
- 如果需要查询数据库，请严格以 `SQL:` 开头，后面直接跟 SQL 语句，例如：
  SQL: SELECT code, name, new_price, change_rate FROM cn_stock_spot WHERE date = (SELECT MAX(date) FROM cn_stock_spot) ORDER BY change_rate DESC LIMIT 10
- 如果不需要查询数据库，请回复：
  NO_SQL
"""

# System prompt for the natural-language answer step
SYSTEM_PROMPT_ANSWER = """你是InStock股票系统的数据分析AI助手。请根据用户的问题和提供的数据库查询结果，用清晰易懂的中文进行分析和回答。

注意事项：
1. 请用中文回答。
2. 如果数据包含股票代码和名称，请在回答中同时列出。
3. 金额单位为元，涨跌幅为百分比。
4. 如果数据为空，请说明可能的原因（如非交易日、数据未更新等）。
5. 对数据进行合理的分析和总结，不要只是简单罗列。
6. 适当使用表格或列表来组织数据，使回答更易读。
"""


# ---------------------------------------------------------------------------
# Helper: call OpenAI-compatible Chat Completions API (non-streaming)
# ---------------------------------------------------------------------------
def _chat_completion(messages: list[dict], temperature: float = 0.1) -> str:
    """Send messages to the LLM and return the assistant text (non-streaming)."""
    url = f"{AI_BASE_URL.rstrip('/')}/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {AI_API_KEY}",
    }
    payload = {
        "model": AI_MODEL,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": 1024,
        "stream": False,
    }
    resp = requests.post(url, headers=headers, json=payload, timeout=60)
    resp.raise_for_status()
    data = resp.json()
    return data["choices"][0]["message"]["content"].strip()


# ---------------------------------------------------------------------------
# Helper: stream Chat Completions via SSE and yield content chunks
# ---------------------------------------------------------------------------
def _chat_completion_stream(messages: list[dict], temperature: float = 0.7):
    """Yield content delta strings from a streaming Chat Completions call."""
    url = f"{AI_BASE_URL.rstrip('/')}/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {AI_API_KEY}",
    }
    payload = {
        "model": AI_MODEL,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": 4096,
        "stream": True,
    }
    with requests.post(url, headers=headers, json=payload, timeout=120, stream=True) as resp:
        resp.raise_for_status()
        resp.encoding = 'utf-8'
        for line in resp.iter_lines(decode_unicode=True):
            if not line:
                continue
            # SSE lines look like "data: {...}" or "data: [DONE]"
            if line.startswith("data: "):
                data_str = line[6:]
                if data_str.strip() == "[DONE]":
                    break
                try:
                    chunk = json.loads(data_str)
                    delta = chunk.get("choices", [{}])[0].get("delta", {})
                    content = delta.get("content")
                    if content:
                        yield content
                except (json.JSONDecodeError, IndexError, KeyError):
                    continue


# ---------------------------------------------------------------------------
# Helper: parse the LLM SQL-step response
# ---------------------------------------------------------------------------
def _parse_sql_response(response_text: str) -> str | None:
    """Return the SQL string if the response contains one, otherwise ``None``."""
    text = response_text.strip()
    if text.upper().startswith("NO_SQL") or text.upper() == "NO_SQL":
        return None

    # Try to find "SQL:" prefix
    match = re.search(r'SQL:\s*(.+)', text, re.DOTALL | re.IGNORECASE)
    if match:
        sql = match.group(1).strip()
        # Remove possible markdown code fences
        sql = re.sub(r'^```(?:sql)?\s*', '', sql)
        sql = re.sub(r'\s*```$', '', sql)
        return sql.strip()

    # Fallback: if the entire response looks like a SELECT, treat it as SQL
    if text.upper().lstrip().startswith("SELECT"):
        return text.strip()

    return None


# ---------------------------------------------------------------------------
# Handlers
# ---------------------------------------------------------------------------
class ChatPageHandler(webBase.BaseHandler, ABC):
    """Render the chat page."""

    @tornado.web.authenticated
    @gen.coroutine
    def get(self):
        self.render("chat.html",
                    ai_configured=bool(AI_API_KEY),
                    leftMenu=webBase.GetLeftMenu(self.request.uri))


class ChatApiHandler(webBase.BaseHandler, ABC):
    """SSE streaming endpoint for the AI chat pipeline.

    Receives JSON: ``{"messages": [...], "question": "..."}``
    Responds with SSE events:
        ``data: {"content": "chunk"}\n\n``
    Terminated by:
        ``data: [DONE]\n\n``
    """

    @tornado.web.authenticated
    def post(self):
        # ---- Set up SSE headers ----
        self.set_header("Content-Type", "text/event-stream; charset=UTF-8")
        self.set_header("Cache-Control", "no-cache")
        self.set_header("Connection", "keep-alive")
        self.set_header("X-Accel-Buffering", "no")

        try:
            body = json.loads(self.request.body)
        except (json.JSONDecodeError, TypeError):
            self._send_sse_error("Invalid request body.")
            return

        messages = body.get("messages", [])
        question = body.get("question", "")

        if not question and messages:
            # Fall back to last user message
            for msg in reversed(messages):
                if msg.get("role") == "user":
                    question = msg.get("content", "")
                    break

        if not question:
            self._send_sse_error("No question provided.")
            return

        if not AI_API_KEY:
            self._send_sse_error("AI service is not configured. Please set AI_API_KEY environment variable.")
            return

        # ---- Step 1: Ask the LLM to generate SQL (non-streaming) ----
        sql_messages = [
            {"role": "system", "content": SYSTEM_PROMPT_SQL},
        ]
        # Carry over conversation context (limit to last 10 messages for token budget)
        for msg in messages[-10:]:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            if role in ("user", "assistant") and content:
                sql_messages.append({"role": role, "content": content})

        # Ensure the current question is the last user message
        if not sql_messages or sql_messages[-1].get("content") != question:
            sql_messages.append({"role": "user", "content": question})

        try:
            sql_response = _chat_completion(sql_messages)
        except requests.exceptions.Timeout:
            self._send_sse_error("AI service request timed out. Please try again.")
            return
        except requests.exceptions.ConnectionError:
            self._send_sse_error("Unable to connect to AI service. Please check AI_BASE_URL configuration.")
            return
        except requests.exceptions.HTTPError as e:
            logging.error(f"ChatApiHandler AI HTTP error in SQL step: {e}")
            self._send_sse_error(f"AI service returned an error: {e.response.status_code}")
            return
        except Exception as e:
            logging.error(f"ChatApiHandler unexpected error in SQL step: {e}")
            self._send_sse_error("An unexpected error occurred while communicating with the AI service.")
            return

        # ---- Parse LLM output ----
        sql = _parse_sql_response(sql_response)

        if sql is not None:
            # Validate and sanitise the SQL
            try:
                sql = _validate_sql(sql)
            except ValueError as e:
                self._send_sse_error(f"The generated SQL is not allowed: {e}")
                return

            # Execute the SQL against the database
            try:
                rows = self.db.query(sql)
                result_data = json.dumps(rows, cls=_ChatEncoder, ensure_ascii=False)
            except Exception as e:
                logging.error(f"ChatApiHandler SQL execution error: {e}")
                error_msg = f"SQL execution error: {e}\n\nGenerated SQL:\n```sql\n{sql}\n```"
                self._stream_plain_text(error_msg)
                return

            # Build messages for the answer step
            if not rows:
                data_summary = "The query returned no data. Possible reasons: non-trading day, data not yet updated, or no matching records."
            else:
                data_summary = result_data

            answer_messages = [
                {"role": "system", "content": SYSTEM_PROMPT_ANSWER},
                {"role": "user", "content": (
                    f"User question: {question}\n\n"
                    f"Executed SQL:\n```sql\n{sql}\n```\n\n"
                    f"Query result ({len(rows)} rows):\n{data_summary}"
                )},
            ]
        else:
            # NO_SQL path: answer the question directly
            answer_messages = [
                {"role": "system", "content": SYSTEM_PROMPT_ANSWER},
            ]
            for msg in messages[-10:]:
                role = msg.get("role", "user")
                content = msg.get("content", "")
                if role in ("user", "assistant") and content:
                    answer_messages.append({"role": role, "content": content})
            if not answer_messages or answer_messages[-1].get("content") != question:
                answer_messages.append({"role": "user", "content": question})

        # ---- Step 2: Stream the natural-language answer ----
        try:
            for chunk in _chat_completion_stream(answer_messages):
                self._send_sse_chunk(chunk)
        except requests.exceptions.Timeout:
            self._send_sse_error("AI service timed out while generating the answer.")
            return
        except requests.exceptions.ConnectionError:
            self._send_sse_error("Lost connection to AI service while streaming.")
            return
        except requests.exceptions.HTTPError as e:
            logging.error(f"ChatApiHandler AI HTTP error in answer step: {e}")
            self._send_sse_error(f"AI service error during answer generation: {e.response.status_code}")
            return
        except Exception as e:
            logging.error(f"ChatApiHandler unexpected error in answer step: {e}")
            self._send_sse_error("An unexpected error occurred while generating the answer.")
            return

        # ---- End of stream ----
        self._send_sse_done()
        self.finish()

    # -- SSE helpers ----------------------------------------------------------

    def _send_sse_chunk(self, content: str) -> None:
        """Write a single SSE data event with a content payload."""
        payload = json.dumps({"content": content}, ensure_ascii=False)
        self.write(f"data: {payload}\n\n")
        self.flush()

    def _send_sse_done(self) -> None:
        """Write the terminal SSE event."""
        self.write("data: [DONE]\n\n")
        self.flush()

    def _send_sse_error(self, message: str) -> None:
        """Send an error message as SSE content and close the stream."""
        self._send_sse_chunk(message)
        self._send_sse_done()
        self.finish()

    def _stream_plain_text(self, text: str) -> None:
        """Stream a plain text string as SSE and close."""
        self._send_sse_chunk(text)
        self._send_sse_done()
        self.finish()
